name: Historical Data Backfill (Hourly)

on:
  schedule:
    # Run every hour to progressively backfill 30 days of data
    - cron: '0 * * * *'  # Every hour at minute 0
  workflow_dispatch:
    inputs:
      allow_fresh_state:
        description: "Allow run to proceed without prior state artifact (first run only)"
        required: false
        default: "false"

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Safety timeout for each run
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-actions.txt

      - name: Create data directory
        run: mkdir -p data

      - name: Download state file from previous run
        continue-on-error: true  # Handle missing artifact explicitly in next step
        uses: actions/download-artifact@v4
        with:
          name: backfill-state
          path: data/

      - name: Validate or initialize state file
        run: |
          if [ -f data/backfill_state.json ]; then
            echo "Found existing backfill_state.json after download step."
            exit 0
          fi

          # No state found; allow only when explicitly permitted
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ inputs.allow_fresh_state }}" = "true" ]; then
            echo "No prior state found; allow_fresh_state=true -> initializing default state."
            echo '{"completed_windows": [], "current_window": 0, "total_windows": 15}' > data/backfill_state.json
            exit 0
          fi

          echo "No backfill_state.json found and allow_fresh_state is not enabled. Failing to avoid running without state." >&2
          exit 1

      - name: Log current backfill window
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          state_path = Path("data/backfill_state.json")
          if not state_path.exists():
              print("No state file present; run will initialize a default state.")
          else:
              try:
                  state = json.loads(state_path.read_text())
                  current = state.get("current_window")
                  total = state.get("total_windows")
                  completed = len(state.get("completed_windows", []))
                  print(f"Starting backfill at window {current} of {total} (completed windows: {completed}).")
              except Exception as exc:
                  print(f"Could not read backfill_state.json: {exc}")
          PY

      - name: Run backfill script
        env:
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_RAW_KEY: ${{ secrets.S3_RAW_KEY }}
          S3_PROCESSED_KEY: ${{ secrets.S3_PROCESSED_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          SEARCH_TERMS: "Data Scientist,Machine learning engineer,AI engineer,Data Analyst,Data Engineer"
          LOCATIONS: "United States,Remote"
          RESULTS_PER_SITE: "400"
        run: |
          python scripts/backfill_historical.py

      - name: Ensure state file for upload
        if: always()
        run: |
          if [ ! -f data/backfill_state.json ]; then
            echo "State file missing after run; creating default to allow artifact upload." >&2
            echo '{"completed_windows": [], "current_window": 0, "total_windows": 15}' > data/backfill_state.json
          else
            echo "State file present; ready to upload."
          fi

      - name: Save state for next run
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backfill-state
          path: data/backfill_state.json
          retention-days: 7

      - name: Check completion status
        if: success()
        run: |
          if [ -f data/backfill_state.json ]; then
            CURRENT=$(cat data/backfill_state.json | grep -o '"current_window":[0-9]*' | grep -o '[0-9]*')
            TOTAL=$(cat data/backfill_state.json | grep -o '"total_windows":[0-9]*' | grep -o '[0-9]*')
            echo "Progress: $CURRENT/$TOTAL windows complete"
            if [ "$CURRENT" -eq "$TOTAL" ]; then
              echo "âœ… Backfill complete! All windows processed."
            fi
          fi
